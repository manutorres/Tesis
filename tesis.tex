\documentclass[oneside]{book}

\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage{enumerate}
\usepackage{tikz}

\title{Argumentación en sistemas multi-agente} % do change
\author{Leonardo Molas \and Manuel Torres}

\theoremstyle{definition}
\newtheorem{definicion}{Definición}[section]
\theoremstyle{example}
\newtheorem{ejemplo}{Ejemplo}[section]

\newcommand{\ie}{i.\,e.}
\newcommand{\etal}{\mbox{{\em et al.}}}
\newcommand{\eg}{e.\,g.}
\newcommand{\raya}{\rule{\textwidth}{.05mm}}
\newcommand{\eoe}{\begin{flushright}$\Box$\end{flushright}}
\newcommand{\marginnote}[1]{\marginpar{\frame{#1}}}
\newcommand{\new}{\marginpar{\frame{\sc new}}}


\newcommand{\DLP}{\mbox{DeLP}}
\newcommand{\DLPa}{\mbox{DeLP}}
\newcommand{\DLPas}{\mbox{DeLP(a)-strict}}
\newcommand{\DLPans}{\mbox{DeLP(a)-non-strict}}
\newcommand{\dlp}{\mbox{\it de.l.p.}}

\newcommand{\cree}{B}

\newcommand{\no}{\mbox{$\sim$}}
\newcommand{\negda}[1]{\mbox{\textsf{not}$#1$}}
\newcommand{\naf}{\p{$\backslash$+}}
\newcommand{\notj}{{not}}
\newcommand{\comp}[1]{\mbox{$\overline{#1}$}}
\newcommand{\simbcomp}{ $\stackrel{\comp{\ \ }}{\vrule width 0pt height.8ex}$ }

\newcommand{\p}[1]{{\small \tt #1}}

% DLP programs 
% strict rule
\newcommand{\srule}[2]{\mbox{$ #1\;\leftarrow\;#2$}}
%\newcommand{\fact}[1]{\mbox{$ #1$}}  % some cls files have \fact defined for other things 
\newcommand{\facto}[1]{\mbox{$ #1$}} % for compatibility when the reason above holds
% literal
\newcommand{\lit}[1]{\mbox{$ #1$}}
% defesible rule
\newcommand{\drule}[2]{\mbox{$ #1\; \defleftarrow \; #2$}}
\newcommand{\defleftarrow}{{\raise1.5pt\hbox{\tiny\defleft}}}
\newcommand{\defleft}{\mbox{---\hspace{-1.5pt}\raise.05pt\hbox{$<$}}}
% presumption
%\newcommand{\presum}[1]{\drule{#1}{true}}
\newcommand{\presum}[1]{\drule{#1}{}}
% inverted rules
\newcommand{\invleftarrow}{ $\hookleftarrow $ }
\newcommand{\irule}[2]{\mbox{$#1$ \invleftarrow $#2$}}
\newcommand{\dquery}[1]{\drule{}{#1}}

% Donald Nute rules
\newcommand{\rr}[2]{\mbox{$ #1 \Rightarrow #2 $}} % defeasible
\newcommand{\re}[2]{\mbox{$#1 \rightarrow #2 $}} % strict
\newcommand{\de}[2]{\mbox{$ #1 \leadsto #2$}} %defeater

% Programci�n en Logica Extendida
\newcommand{\ple}{\mbox{\sc PLE}}
\newcommand{\extclause}[2]{\mbox{ #1 $\leftarrow$ #2}}
\newcommand{\true}{$true$}

% flecha rebatible para la derecha
\newcommand{\defrightarrow}{\mbox{$\succ\!$---}}
\newcommand{\defarrow}{{\raise1.5pt\hbox{\tiny\defrightarrow}}}


% Argumentos
\newcommand{\ArgA}{\mbox{${\mathcal A}$}}
\newcommand{\Ap}{\mbox{\ArgA$'$}}
\newcommand{\ArgAo}{\mbox{${\mathcal A_0}$}}
\newcommand{\ArgAa}{\mbox{${\mathcal A_1}$}}
\newcommand{\ArgAb}{\mbox{${\mathcal A_2}$}}
\newcommand{\ArgAn}{\mbox{${\mathcal A_n}$}}
\newcommand{\ArgAi}{\mbox{${\mathcal A_i}$}}
\newcommand{\ArgAim}{\mbox{${\mathcal A_{i-1}}$}}
\newcommand{\ArgB}{\mbox{${\mathcal B}$}}
\newcommand{\ArgBo}{\mbox{${\mathcal B_0}$}}
\newcommand{\ArgBa}{\mbox{${\mathcal B_1}$}}
\newcommand{\ArgBb}{\mbox{${\mathcal B_2}$}}
\newcommand{\ArgBk}{\mbox{${\mathcal B_k}$}}
\newcommand{\ArgQ}{\mbox{${\mathcal Q}$}}
\newcommand{\ArgQo}{\mbox{${\mathcal Q_0}$}}
\newcommand{\ArgQa}{\mbox{${\mathcal Q_1}$}}
\newcommand{\ArgQb}{\mbox{${\mathcal Q_2}$}}
\newcommand{\ArgQk}{\mbox{${\mathcal Q_k}$}}
\newcommand{\ArgQn}{\mbox{${\mathcal Q_n}$}}
\newcommand{\ArgQi}{\mbox{${\mathcal Q_i}$}}
\newcommand{\ArgQim}{\mbox{${\mathcal Q_{i-1}}$}}
\newcommand{\AQ}{\mbox{$\langle \ArgA,\ArgQ \rangle $}}
\newcommand{\AoQo}{\mbox{$\langle \ArgAo,\ArgQo \rangle $}}
\newcommand{\AaQa}{\mbox{$\langle \ArgAa,\ArgQa \rangle $}}
\newcommand{\AbQb}{\mbox{$\langle \ArgAb,\ArgQb \rangle $}}
\newcommand{\AnQn}{\mbox{$\langle \ArgAn,\ArgQn \rangle $}}
\newcommand{\AiQi}{\mbox{$\langle \ArgAi,\ArgQi \rangle $}}
\newcommand{\AimQim}{\mbox{$\langle \ArgAim,\ArgQim \rangle $}}
\newcommand{\BaQa}{\mbox{$\langle \ArgBa,\ArgQa \rangle $}}
\newcommand{\BkQk}{\mbox{$\langle \ArgBk,\ArgQk \rangle $}}

\newcommand{\Argum}[2]{\mbox{$\langle #1, #2 \rangle $}}
\newcommand{\AS}[2]{\mbox{$\langle \{#1\}, #2 \rangle $}}

% Sets of rules
\newcommand{\Facts}{\mbox{$\Theta$}}       % Facts
\newcommand{\SRules}{\mbox{$\Omega$}}       % Stricts rules
\newcommand{\SSet}{\mbox{$\Pi$}}       % Stricts rules & facts
\newcommand{\SSg}{\mbox{${\SSet}_G$}}  % Stricts rules without facts 
\newcommand{\SSp}{\mbox{${\SSet}_P$}}  % set of facts
\newcommand{\DD}{\mbox{$\Delta$}}      % Defeasible rules
\newcommand{\SD}{\mbox{$(\SSet,\DD)$}} % sets of rules of a program 
\newcommand{\FSD}{\mbox{$(\Facts,\SRules,\DD)$}} % sets of rules of a program 
\newcommand{\Presumptions}{\mbox{$\Phi$}}   % 
\newcommand{\DDp}{\mbox{$\Delta^{+}$}}  % Defeasible rules and presumptions
\newcommand{\SDp}{\mbox{$(\SSet,\DDp)$}} % sets of rules of a program 
\newcommand{\FSDP}{\mbox{$(\Facts,\SRules,\DD,\Presumptions)$}} % sets of rules of a program 

\newcommand{\FySyD}{\mbox{\Facts\ $\cup$ \SSet\ $\cup$ \DD}}   
\newcommand{\SyD}{\mbox{\SSet\ $\cup$ \DD}}   
\newcommand{\SyA}{\mbox{\SSet\ $\cup$ \ArgA}}
\newcommand{\SyAp}{\mbox{\SSet\ $\cup$ \Ap}}
\newcommand{\SyArga}{\mbox{\SSet\ $\cup$ \Arga}}
\newcommand{\RR}{\mbox{$\mathcal R$}}
\newcommand{\PP}{\mbox{${\mathcal P}$}}
\newcommand{\PPa}{\mbox{${\mathcal P}_1$}}
\newcommand{\PPb}{\mbox{${\mathcal P}_2$}}
\newcommand{\PPc}{\mbox{${\mathcal P}_3$}}
\newcommand{\PPd}{\mbox{${\mathcal P}_4$}}
\newcommand{\FFi}{\mbox{${\mathcal F}_i$}}
\newcommand{\FF}{\mbox{${\mathcal F}$}}

\newcommand{\SyQaQ}{\mbox{$\SSet \cup \{\ArgQa\\,\ArgQ\}$}}

\begin{document}

\maketitle
\tableofcontents

\chapter*{Introducción}

%---

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Preliminares} 

\input{juego}

\input{preliminares_delp}

\input{preliminares_bdi}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Arquitectura} % VER DONDE ES DISEÑO Y DONDE ARQUITECTURA

Este capítulo tiene el objetivo de analizar el diseño y estructura que presenta el 
enfoque de agente propuesto. Primero desde un punto de vista general, para luego 
poner especial énfasis en el módulo dedicado a la toma de decisiones, responsable 
del manejo de las creencias, deseos e intenciones. Serán presentados en detalle los 
componentes básicos del esquema BDI aplicado, así como también las principales 
adaptaciones y agregados realizados en esta implementación particular.

\section{Diseño general}

%\label{sec:diseñoGeneral}

El programa agente presenta una estructura simple en cuanto a su división más general. 
Esto permite su entendimiento a nivel individual, al mismo tiempo que facilita su 
integración en un entorno multi-agente como el enfrentado. La interacción con el entorno 
y el procesamiento inicial de la información recibida finalizan con la generación de una 
serie de creencias que son incorporadas a la base de conocimiento mantenida por el agente. 
Este conjunto de creencias es empleado posteriormente por el módulo encargado de tomar 
decisiones. La forma en que se estructuran los componentes principales es detallada a 
continuación.

\subsection{Estructura básica del agente}

%\label{sec:estructuraBasica}

El programa principal del agente es el encargado de manejar la comunicación con los 
servidores, tanto el del juego como el de percepciones (presentado 
a continuación). También es responsable de parsear y procesar la información contenida 
en la percepción para darle el formato interpretado por la base de conocimientos, y 
enviar la acción que ha sido elegida por el módulo de toma de decisiones.

\begin{figure}
 \centering
\includegraphics[scale=.4]{agent_architecture.eps}

 \caption{Diagrama de la arquitectura del agente. Las líneas punteadas representan el 
 flujo de control, y las líneas contínuas representan el flujo de datos.}
 \label{fig:architecture}
\end{figure}

El servidor de percepciones (SP) es un programa independiente, encargado de unificar las 
percepciones de todos los agentes que se encuentran en ejecución. Recibe sus percepciones 
individuales y retorna a cada uno de ellos el conjunto de datos que aún no poseen, de 
manera que todos los agentes del equipo cuenten con la misma información en cuanto al estado 
del escenario.

En cada iteración de la simulación, el agente recibe un mensaje por parte del servidor 
del juego, el cual contiene la información asociada a la percepción del turno en disputa. 
Este mensaje es parseado y traducido en una estructura que permite manipular los datos 
con mayor facilidad. Los datos son divididos en dos conjuntos, uno ``público'', el cual 
es compartido con los demás agentes del equipo, y uno ``privado''. La sección pública de 
datos es compartida a través del mencionado servidor de percepciones.

El agente une entonces su propia percepción con la percepción global recibida del servidor 
de percepciones, y genera un único conjunto de datos. Esta información es incorporada a la 
base de conocimientos, estableciendo nuevas creencias para el agente.

El módulo de toma de decisiones, analizado en la sección \ref{sec:arquitecturaBDI}, es el 
que implementa el modelo BDI respetado por el agente. Este módulo es consultado en cada 
iteración para obtener la próxima acción a ser ejecutada. Una vez que el flujo de control 
retorna al programa principal, la acción seleccionada es enviada al servidor del juego.

\subsection{Base de conocimiento}

%\label{sec:baseConocimiento}

Como fue mencionado, la percepción del agente en cada iteración es convertida a una 
estructura de datos que permite, de manera más sencilla, manipular y compartir la 
información. Cuando el agente cuenta con todos los datos relativos a las percepciones 
del equipo, la base de conocimiento puede ser actualizada convenientemente. Una colección 
de predicados de Prolog consultados desde el programa principal se encarga de verificar 
que la información existente no resulte sobreescrita, y que información redundante no sea 
incorporada. 

La información que constituye conocimiento certero sobre el estado del escenario es 
almacenada mediante términos, que sirven como argumentos del predicado \texttt{k/1} 
(\textit{knowledge}). Cada uno de los datos de interés es representado mediante un 
término diferente. 
En muchos casos, esta clase de términos incluyen un argumento ligado al número de turno 
en el cual el dato fue percibido. De esta forma, es posible realizar ciertos análisis, 
como por ejemplo, considerar obsoleta la información de una determinada antigüedad.

	% En castellano para mantener el idioma y porque las b() 
	% están así.
\begin{verbatim}    
    k(equipoAgente(Agente, Equipo)).
    k(valorNodo(Nodo, Valor)).
    k(arco(Nodo1, Nodo2, Costo)).
    k(posicionAgente(Agente, Turno, Posición)).
    k(equipoNodo(Turno, Nodo, Dueño)).    
\end{verbatim}

Las creencias que provienen de inferencias y cálculos realizados a partir de información 
ya existente también son almacenadas mediante términos, en este caso argumentos del 
predicado \texttt{b/1} (\textit{beliefs}). Este tipo de creencias es empleado directamente 
por el módulo encargado de la toma de decisiones, y se mantienen vigentes sólo durante el 
turno en el cual fueron generadas. Es decir, que, al finalizar cada turno, son descartadas 
para evitar futuros problemas o inconcistencias.

\begin{verbatim}
    b(estoyEnLaFrontera).
    b(posibleExplorar(Nodo)).
    b(haySaboteador(Nodo)).
\end{verbatim}

Existe cierta información que es formulada de manera hipotética. Se trata de datos 
surgidos de suposiciones realizadas sobre posibles estados futuros del escenario, a partir 
de su estado actual. Este tipo de datos resulta fundamental para facilitar los cálculos 
realizados por los algoritmos que se encargan de buscar formas de maximizar el puntaje 
del equipo. Dado que no constituye información real, sino posible a futuro, se almacena 
mediante argumentos de un predicado especial, \texttt{h/1} (\textit{hypothetical}).

\begin{verbatim}
    h(nodoEquipo(Nodo, Dueño)).
    h(posicion(Turno, Agente, Nodo)).    
\end{verbatim}

Las intenciones surgen del proceso argumentativo explicado más adelante, y son 
representadas utilizando términos. Si la intención no posee argumentos, entonces es 
representada mediante un átomo. En otro caso, se emplea un functor que denota el 
nombre de la intención, acompañado por un argumento. Las acciones, por el contrario, 
son representadas a través de listas. El primer elemento de la lista es un atómo denotando 
el tipo de acción. Y el resto de la lista contiene, ocacionalmente, un término que 
indica el argumento de la acción, como por ejemplo el nombre de un nodo o un agente.
Los planes son representados mediante listas de acciones, es decir, listas de listas.

Contrario a lo que ocurre con las creencias, tanto las intenciones como los planes 
constituyen información que debe perdurar en la base de conocimiento tantos turnos 
como sea necesario. Para este tipo de datos se emplean hechos específicos que cuentan 
con un único argumento.

\begin{verbatim}
    intencion(explorar(vertex7)).
    plan([[recharge], [goto, vertex7], [survey]]).
\end{verbatim}

\section{Arquitectura BDI} %CAMBIAR: Toma de decisiones?

\label{sec:arquitecturaBDI}

El módulo de \textbf{Toma de Decisiones} es consultado por el programa 
principal, obtiene la próxima acción a ser ejecutada, y la retorna para que 
pueda ser enviada. Esta es una secuencia que se reitera en cada uno de los 
turnos de la simulación, con la característica de que cuando es necesario 
plantear y planificar una nueva meta, intervienen una serie de componentes 
especiales, que difieren de aquellos involucrados cuando se cuenta con una 
meta ya planificada. 

En la Fig. \ref{fig:agentProlog} se pueden observar las diferentes partes de la
arquitectura interna de este módulo, sus interacciones el exterior (el 
\textbf{Módulo principal}), y sus interacciones internas con sus componentes,
tanto bases de datos como sub-módulos. Cada uno de estos componentes es 
descrito en esta sección.

\begin{figure}
% \includegraphics[width = 1.2 \textwidth]{agentprolog.eps}
 \includegraphics[width=\textwidth]{agent_prolog.eps}
 \caption{Diagrama de la arquitectura del módulo de \textbf{Toma de Decisiones}.}
 \label{fig:agentProlog}
\end{figure}

\subsection{Seteo de creencias}

\label{sec:seteoCreencias}

El seteo de creencias es llevado a cabo cada vez que el agente se dispone a 
seleccionar una nueva intención. Incluye la generación de aquellos datos que pueden 
permitir al agente realizar una elección lo más acertada posible. Se trata de 
inferencias realizadas en base al estado del escenario, es decir, aquella información 
que, como fue mencionado, es almacenada en \texttt{b/1}. No forma parte de este proceso 
la información proveniente de la percepción, las cuales denominaremos \textbf{creencias
simples}, ya que el estado del entorno es actualizado 
en cada turno de manera previa. Todas las creencias son explicadas en 
la sección \ref{sec:creencias}.

\paragraph{Creencias generales.}

Existe un conjunto de creencias que resultan de utilidad general para todo el proceso 
de decisión. Entre los datos incluidos, se encuentra el puntaje que están 
aportando las zonas armadas, la diferencia de puntos que puede producirse si el agente 
abandona su posición, y la seguridad que brindan las distintas ubicaciones posibles en 
cuanto a la presencia de agentes saboteadores enemigos. 

\paragraph{Deseos.}

El proceso de toma de decisión conlleva el 
pesaje de todos los posibles deseos del agente, y la posterior selección del más beneficioso. 
Dichos deseos surgen de un conjunto predefinido, y pueden, según sea el caso, estar 
instanciados con diferentes entidades del juego, como agentes o nodos. Para que esta 
selección sea posible, es necesario determinar, de manera previa, qué deseos e instanciaciones 
son realmente factibles, y por lo tanto deben ser tenidos en cuenta, y cuales pueden ser 
descartados anticipadamente.
Para esto se analizan distintas condiciones como, por ejemplo, la distancia a un nodo 
que no ha sido explorado. Si el nodo se encuentra a una distancia que supera una cota 
pre-establecida, entonces el deseo de explorar ese nodo no es contemplado.
Los deseos e instanciaciones considerados factibles son seteados en la base de conocimiento.

\paragraph{Creencias específicas.} % Seteo de beliefs para cada deseo.

Junto con los deseos a ser evaluados, es necesario incluir en la base de conocimiento 
un conjunto de creencias relacionadas a estos deseos. Entre las más importantes, se 
encuentran las distancias que existen desde la posición actual del agente a los distintos 
vértices de interés, y la diferencia de puntaje que se produce en caso que el agente se desplace 
a dichas ubicaciones. Estos datos resultan fundamentales, ya que afectan directamente la 
valuación que se realiza de cada deseo, y por lo tanto la posterior selección. 
En esta etapa, también se produce el seteo de datos requeridos posteriormente, como son 
los caminos a los diferentes vértices analizados. 

\paragraph{Creencias defensivas.} % Seteo de beliefs en caso de agente deshabilitado.

Cuando el agente se encuentra en una situación de peligro, esto es, no posee el rol de 
saboteador y hay un saboteador enemigo en su posición, o fue atacado en el turno anterior, 
el conjunto de creencias seteadas se reduce. En estos casos, sólo son tenidos en cuenta 
los nodos vecinos, dado que representan las vías de escape más rápidas; son calculadas 
las distancias a estos (en cantidad de turnos), y las diferencias de puntaje que produciría 
el desplazamiento del agente. Esto tiene el objetivo de minimizar la cantidad de deseos 
considerados: sólo son evaluadas la posibilidad de permanecer en la misma ubicación 
(si el beneficio en puntaje es considerable), y las distintas alternativas de defensa 
propia que pueden llevar al agente a superar el peligro.

\subsection{Argumentación}

\label{sec:argumentacion}

Una vez finalizado el seteo de creencias, el agente procede a la selección de la próxima 
intención. Para esto, se toma cada uno de los deseos marcados como factibles en la base 
de conocimiento, y se consulta al módulo de argumentación (implementado en DeLP) sobre éstos. 
Dicho módulo
%considera que existen razones para creer realizables sólo aquellos deseos que satisfacen 
%sus condiciones. 
devuelve como garantizados los deseos que son realizables, es decir aquellos que satisfacen
una serie de condiciones.
Para éstos, obtiene un valor que representa su peso, en términos del 
beneficio que conllevan para el equipo. El deseo que presenta el mayor peso entre los 
analizados, se convierte en la nueva intención del agente, la cual es almacenada hasta ser 
alcanzada o reemplazada.

Tanto la evaluación como el pesaje de los deseos, son llevados a cabo empleando \textit{argumentación} 
en un módulo especial, implementado con la ayuda de \textit{DeLP}. 
Detalles sobre la implementación y como la argumentación es aplicada en el proceso de 
razonamiento, son estudiados en el capítulo dedicado a la Toma de Decisiones. %referencia, cambiar nombre?

\subsection{Planificación}

%\label{sec:planificacion}

La planificación consiste en obtener la secuencia de acciones que llevan al cumplimiento 
de la intención propuesta. Esta lista está compuesta por las acciones que le permiten al 
agente posicionarse en el nodo deseado, y, en algunos casos, una acción concreta a realizar. 
Como se dijo anteriormente, en la etapa de seteo de creencias, todos los caminos hallados 
por el algoritmo de búsqueda son almacenados. Dicho algoritmo fue implementado de manera 
tal que los caminos no están constituidos por nodos o vértices, sino por una secuencia 
optimal de acciones, que tiene en cuenta no sólo el nodo destino, sino también los recursos 
del agente, y la meta final a realizar (en caso de haber una acción final). De esta forma, 
cualquiera haya sido la intención elegida, el agente cuenta en su base de conocimiento 
con el plan necesario para cumplirla. La planificación se resume entonces a tomar las 
acciones correspondientes, y establecerlas efectivamente como el plan a seguir.

Alternativamente, esta etapa puede introducir ciertas acciones con el objetivo de optimizar 
el uso del turno. En aquellas situaciones en que el agente se dispone a permanecer inactivo, 
la acción nula (\texttt{skip}) puede ser reemplazada por la acción de recargar energía, si es que 
esta resulta más productiva.

\subsection{Ejecución}

\label{sec:ejecucion}

Dado que el plan se encuentra almacenado de manera completa y ordenada, la ejecución se 
realiza en forma directa. Se toma la próxima acción, es decir, la primera acción del plan 
restante, y se la retorna al módulo principal del programa. Este se encarga posteriormente 
de enviarla al entorno, para que se convierta finalmente en la siguiente acción realizada 
por el agente.

\subsection{Condición de corte}

\label{sec:condicionDeCorte}

Existen situaciones en las que el paso de los turnos genera que el cumplimiento de una 
meta se vuelva inalcanzable, innecesario, riesgoso, o menos productivo de lo previsto, por 
lo que resulta más beneficioso abortar el plan existente, y seleccionar una nueva intención. 
Ésta es una etapa de verificación, que tiene como objetivo la detección de este tipo de 
situaciones. Es ejecutada sólo en aquellos turnos en los que el agente se encuentra 
siguiendo el plan de una intención previamente determinada.

Cada deseo o esquema de deseo cuenta con una serie de \textbf{condiciones de corte}, que 
son evaluadas al inicio de cada turno, en caso de existir un plan establecido. Si se verifica 
que alguna de estas condiciones se satisface, entonces la intención es descartada, y el 
agente ingresa en un nuevo proceso de selección. 
Entre las condiciones de corte tenidas en cuenta, se encuentran: 

\begin{itemize}
	\item Que haya pasado una determinada cantidad de turnos desde el inicio del plan.
	\item Que el agente se encuentre deshabilitado.
	\item Que haya sido atacado o se encuentre amenazado por un enemigo.
	\item Que la meta haya sido alcanzada por un compañero de equipo.
\end{itemize}

\subsection{Re-planificación}

La fase de re-planificación consiste en elaborar nuevamente el plan que permite alcanzar 
la meta propuesta, sin modificar dicha meta. Este paso, como el anterior, se realiza en 
los turnos en los que el agente posee un plan pre-calculado. Dado que en estos turnos no 
es necesaria la obtención de una nueva intención, proceso que implica el mayor insumo de 
tiempo, la inclusión de la re-planificación no afecta el funcionamiento normal del agente, 
en términos de tiempo de ejecución. 

Por el contrario, existe una mejora en el desempeño del equipo, surgida de un mejor 
aprovechamiento de la información percibida. Los agentes actualizan su información sobre 
el estado del mundo en cada turno. Datos como el estado en que se hallan los recursos del 
agente, la incorporación de nodos y arcos hasta el momento desconocidos, o las nuevas 
ubicaciones de los otros agentes, permiten elaborar planes más precisos y ajustados a la 
realidad que los originalmente diseñados. Así, los agentes son capaces de cumplir sus 
metas con mayor facilidad, o abortarlas si es necesario.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Argumentación}

En esta sección se expandirá lo explicado en el capítulo anterior, relacionado a 
la toma de decisiones. Esto es, generación de los deseos, su estructura, la selección de la
intención, en particular su proceso de argumentación (derrotas, tanto por peso como 
propias), todo con ejemplos concretos del programa realizado. 

\section{Modelo de argumentación} 

\label{sec:modeloDeArgumentacion}

Sin inmiscuirse en los detalles de la implementación, la idea que llevamos a cabo en el 
desarrollo del programa fue un sistema en el que existen un tipo especial de argumentos,
que constituyen los argumentos de deseos, los cuales contienen un valor numérico.
Este valor es el \textbf{peso} del deseo que es garantizado por el argumento de deseo. 

El soporte de cada argumento de deseo, está formado por reglas rebatibles que representan
razones para considerar la aplicación del deseo beneficiosa para el agente y/o el equipo.
A su vez, estos argumentos requieren de la existencia de distintos hechos en la base de 
datos consistente, para estar garantizados. Se trata de creencias, algunas de las cuales
contienen cuantificaciones acerca del estado del mundo actual (por 
ejemplo, el valor de un nodo o el costo de un arco). Estos valores son utilizados en la
determinación del peso del deseo aplicando un cálculo \textit{ad hoc}, %cursiva
que será explicada luego.

Dado que sólo resultará seleccionado un único deseo, se contraponen todos los argumentos 
de deseo garantizados, generando ataques entre sí. Entre dos argumentos enfrentados, será
derrotado el de menor peso. Por lo tanto, quedará como no derrotado un solo argumento, 
aquel con el mayor peso. Estos ataques, en \textit{DeLP}, pueden ser programados de la 
siguiente manera:

$$ \sim X \leftarrow Y$$ 

Siendo $X$ e $Y$ cualquier deseo. Este tipo de reglas estrictas, a las que
denominaremos \textit{reglas de cancelación mutua}, se repite 

para todos los deseos existentes.

Entre los criterios de comparación comunes de \textit{DeLP} (estos son \textit{Especificidad} y 
\textit{Derrotadores a asunciones}) no existe la capacidad de comparar por pesos. 
Por esta razón, se utiliza un nuevo criterio, el cual 
denominaremos \textit{Mayor Peso}. Como su nombre lo indica, compara los pesos de los 
argumentos, si estos existen (y estos sólo existen en los argumentos de deseos). Los 
argumentos con mayor peso derrotan a los de menor.

En el caso de que el peso de dos argumentos sea el mismo, todavía existiría el problema 
de los bloqueos. Esto generaría un problema si justo se tratará de los más pesados, ya 
que ninguno de los dos (o más) deseos estarían garantizados o derrotados, y la consulta
por deseo no devolvería ningún resultado. Por esta razón, se extiende el criterio 
\textit{Mayor Peso}\ para que contemple como caso especial las igualdades de peso. En 
estos casos, se hará una comparación por orden lexicográfico de los argumentos, ya que
no interesa cuál de los dos resulta ganador. 

En la figura %mamarracho
se muestra este concepto de derrotas. % explicar

%figura mamarracho

\section{Tipos de argumento}

\label{sec:tiposArgumento}

% En el subprograma de toma de decisiones (a partir de ahora subprograma \textit{DeLP}, o simplemente
% \textit{DeLP}), se utilizaron dos tipos de argumentos. En esta sección, se explicará su uso.

El esquema anterior fue el propuesto, pero no exactamente el implementado, ya que
realizamos modificaciones para optimizar los tiempos de ejecución del programa. Sin 
embargo, el concepto de tener varios tipos de argumentos, incluyendo el de deseos, con sus
pesos, se mantuvo. En esta sección se explicarán más en detalle.

\subsection{Argumentos de soporte}

\label{sec:argumentosSoporte}

Estos argumentos sirven de soporte para los argumentos de deseo, o los derrotan mediante
el ataque a alguno de sus subargumentos. 
No incluyen peso, aunque pueden contener los valores que serán utilizados para calcular 
éstos, entre otros usos.


\subsubsection{Creencias Generadas}

Este conjunto es asertada en el seteo de creencias, como fue explicado en %REFFFFFFF
. Se trata de hechos \textit{DeLP}, cuya cabeza contiene la signatura encerrada dentro
de un functor \texttt{b/1}. Esto se hizo para facilitar la búsqueda y eliminación de
estos hechos. Un ejemplo de éstos sería la siguiente regla:

\begin{verbatim}
b(~esSeguro(vertex34))<-true.
\end{verbatim}

Este hecho determina que en el turno actual, la posición \texttt{vertex34} es peligrosa,
ya que se encuentra un saboteador enemigo parado en él. Varios deseos tienen en cuenta
que la posición a la que irán sea segura, ya que sino entrarían en un posible combate.
Luego, un deseo que necesite tener como parámetro un vértice seguro, lo descartaría.

La existencia o no de estos hechos corresponde con una semántica binaria. Otros tipos de
creencias en el subprograma \textit{DeLP} no se corresponden con ella, a pesar de corresponderse
con el esquema anterior. Se trata de creencias que exponen cuantificaciones a ser 
tenidas en cuenta para el cálculo de los pesos. Un ejemplo de estas creecias es el 
siguiente:

\begin{verbatim}
b(difPuntosSinMi(0))<-true.
\end{verbatim}

En este caso, el hecho expone la cantidad de puntos que se podrían llegar a perder si el
agente se va de su vértice (ya sea porque se mueve o porque deja de estar activado). Esa
cantidad se tiene en cuenta por los argumentos de deseos, para descartar los que generen
mucha pérdida de puntos. ``Mucha pérdida'' se corresponde con un concepto difuso, a
diferencia de los hechos explicados antes. Este valor será el parámetro de una función
de varias variables, que será explicado luego, el cual genera el valor que se usa como
peso del argumento de deseo. Perder cero puntos, como expone el hecho de más arriba, es el
caso ideal de un deseo, por lo que las metas que lo consideren tendrán un puntaje
relativamente alto.

Existen otras creencias de este tipo, que pueden tener otros parámetros además del valor
numerico, como por ejemplo un vértice. El hecho \texttt{difPuntos} es un ejemplo de esto.
Es parecido al anterior, con la diferencia que se instancia con un vértice al cual es
posible llegar en una cantidad pequeña de turnos, y su otro parámetro representa la
cantidad de puntos que ganaría (o perdería, si el valor es negativo) el agente al moverse
a dicho vértice. Por esta razón, puede haber varias de estos hechos instanciados con
distintos vértices la vez.

\subsubsection{Creencias indirectas}

\label{sec:creeciasIndirectas}

Hay algunas creencias que no se generan en tiempo de ejecución del programa Prolog, sino
que se calculan cuando se ejecuta el subprograma \textit{DeLP}. Se calculan en base a las creencias
expuestas en la sección anterior. Un ejemplo de éstas es la de la Fig. 
\ref{fig:creenciaIndirecta}.

\begin{figure}
\begin{verbatim}
puedoHacerParry -<
    myRole(repairer).

puedoHacerParry -<
    myRole(saboteur).

puedoHacerParry -<
    myRole(sentinel).

~puedoHacerParry <-
    myEnergy(Energy),
    less(Energy,2).
\end{verbatim}

\caption{Ejemplo de una creencia indirecta.}
\label{fig:creenciaIndirecta}

\end{figure}

En este caso, la creencia \texttt{puedoHacerParry}\ se calcula en base al rol del 
agente,
así como también de la energía del agente. Esto es porque no todos los roles tienen la
acción asociada, por lo que se listan las que sí lo pueden. Por otro lado, el agente
no puede hacer \textit{parry}\ si no tiene por lo menos dos puntos de energía, lo cual
es expresado por la última regla.

\subsubsection{Funciones aritméticas y lógicas}

En la última línea de la Fig. \ref{fig:creenciaIndirecta}, se utiliza la función 
\texttt{less/2}, que es una función de comparación. (En ese caso, devuelve lo mismo
que $Energy < 2$.) Ése es un ejemplo de las diferentes funciones aritméticas y 
lógicas que se encuentran en el subprograma \textit{DeLP}.

Estas reglas se encuentran fuera del lenguaje \textit{DeLP}, y fueron implementadas 
aprovechando su capacidad de consultar a Prolog, utilizando \textit{built in's}.
En la figura \ref{fig:funciones}\ se ejemplifica la manera en que se han 
implementado.

\begin{figure}
\begin{verbatim}    
is_a_built_in(less(_X,_Y)).
is_a_built_in(add(_X,_Y,_Z)).

add(X,Y,Z :- Z is X + Y.
less(X,Y) :- X < Y.
\end{verbatim}

\caption{Ejemplo de una función aritmética y una lógica.}
\label{fig:funciones}
\end{figure}

\subsubsection{Cálculo de pesos}

Utilizando la misma idea que la funciones ariméticas de la sección anterior, el
cálculo de los pesos de los argumentos de deseos se logró utilizando \textit{built 
in's}. Existe uno por cada regla de deseo, salvo que esté fijo, en cuyo caso 
este valor simplemente se encontrará en vez de la varialbe \texttt{Peso}. Un 
ejemplo extraído del código se encuentra en la Fig. \ref{fig:calculoDePeso}.

\begin{figure}
\begin{verbatim}
is_a_built_in(aumentoPeso(_, _, _, _, _)).

aumentoPeso(Turnos, DifPuntos, EnergiaRestante, CoefFase, Peso) :-
    Value is (DifPuntos * 10 + (10 - Dist) ** 2 + EnergyLeft) * 
    		CoefFase.
\end{verbatim}

\caption{Ejemplo del cálculo del peso de un argumento de deseo.}
\label{fig:calculoDePeso}
\end{figure}

En este ejemplo, se calcula el peso del deseo \emph{aumento}. Para esto, se utilizan
varios parámetros, entre las cuales se encuentran la cantidad de turnos que 
conllevará realizarlo, y la diferencia de puntos que genera.

Todas estas funciones cumplen con el protocolo de mantener el nombre del deseo,
seguido de ``Peso'' como nombre. A su vez, mantiene todos los parámetros 
necesarios como argumentos, seguido de la variable \texttt{Peso}, en la cual se 
retornará dicho valor.

\subsubsection{Coeficientes y otros valores auxiliares}

En la fórmula de la figura \ref{fig:calculoDePeso}\ se utiliza el valor 
\texttt{CoefFase}. Este valor no pertenece a lo obtenido en las percepciones, ni
directa ni indirectamente, sino que se trata de un valor preestablecido (o
\textit{harcodeado}). Pertenece a esta categoría aparte de creencias predefinidas,
cuyos valores modifican los pesos ya sea de manera aditiva/substractiva, o 
porcentualmente (como es el caso de \texttt{CoefFase}).

En particular, este valor se refiere a un coeficiente que se le aplica a varios
pesos de deseos, que representa la utilidad de cada deseo en la fase actual. El 
concepto de \textit{``fase''}\ se trata de un modificador más del comportamiento
del agente, que cambia de acuerdo a diferentes parámetros, como por ejemplo una
determinada cantidad de turnos, proporción de muertes, porcentaje de mapa explorado,
etc. Fue implementada la interfaz para utilizarla, pero no se expandió a más de una
fase inicial de exploración, por cuestiones de falta de tiempo.

Otros valores caen dentro de esta categoría, como \texttt{agentRolePoints/3}.
Se utiliza para agregar (o sustraer) una determinada cantidad de turnos, dado el
deseo y el rol del agente al cual está apuntado el deseo. Esto sirve para modificar el 
comportamiento de una manera sencilla y modular, para los deseos y roles que los 
necesiten.

Se necesitarían $|D| \times |R|$ reglas para determinar estos valores, siendo $D$
y $R$ los conjuntos de deseos y roles respectivamente. Ésto se simplificó utilizando
un valor por defecto neutral ($0$). Este comportamiento es mostrado
en la Fig. \ref{fig:agentRolePoints}. En éste se muestra la implementación del caso
general, y el caso especial del deseo \emph{reparar}\ para el rol \emph{repairer}.
Agregarle 70 puntos al peso implica darle mayor importancia reparar a otro reparador,
antes que hacerlo con cualquier otro agente.

\begin{figure}
\begin{verbatim}
% en arg.delp
agentRolePoints(_, _, 0) -< true.
	
~agentRolePoints(D, R, 0) <- 
	agentRolePoints(D, R, V),
	notEqual(V, 0).
    
% en repairer.delp
agentRolePoints(reparar, repairer, 70) <- true.
\end{verbatim}
\caption{Implementación de \texttt{agentRolePoints/3}, para el caso general, y para el 
deseo de \emph{reparar}\ para el \emph{repairer}}
\label{fig:agentRolePoints}
\end{figure}


\subsection{Argumentos de Deseos}

\label{sec:argumentosDeseos}

En esta sección, se darán las diferentes definiciones que se utilizarán para dar marco a los
argumentos de deseos, que son los argumentos que modelan el comportamiento de los agentes.
%
%\subsubsection{Modelos de Deseos}

\begin{definicion}
	Un \textbf{modelo de deseo}\ es un literal no negado, 
	y tiene por lo menos un parámetro. Estos parámetros
	no deben estar instanciados.
\end{definicion}


El nombre del functor del modelo de deseo connota el deseo que se quiere representar. Los 
modelos de deseos son las cabezas de las reglas rebatibles que se encuentran en el código 
de DeLP de los agentes. 

%\subsubsection{Deseos}

\begin{definicion}
	Un \textbf{deseo} es un modelo de deseo con sus parámetros instanciados.
\end{definicion}

La interfaz con Prolog consultará por estos deseos al programa DeLP, manteniendo el deseo con
mayor peso para ser seleccionado como \emph{intención}. Los otros parámetros contienen 
información referente al deseo, como por ejemplo el vértice o un agente al cual hace 
referencia, y son los necesarios y suficientes para determinar unívocamente el deseo. Esto 
es, no existen dependencias funcionales (en el sentido de \emph{base de datos}) entre los 
parámetros.


\begin{definicion}
Una {regla de deseo} es una regla rebatible o una regla estricta cuya cabeza es un modelo 
de deseo.
\end{definicion}

El programa \textit{DeLP} está conformado por una serie de reglas de deseo, que modelan
el comportamiento del agente, así como de otras reglas que serán utilizadas por los 
argumentos de soporte.

Como fue explicado en la sección \ref{sec:modeloDeArgumentacion}, el tipo más importante de 
reglas en el subprograma \textit{DeLP} son los de argumentos de deseos. 

\begin{definicion}
	Un \textbf{argumento de deseo} es un argumento cuya conclusión
	es un deseo.
\end{definicion}


\section{Selección de la Intención}

El proceso de selección se realiza mediante la consulta al programa \textit{DeLP} por cada
uno de los deseos, como se explicó en la sección \ref{sec:argumentacion}. 
En esta sección se detalla como el modelo de argumentación planteado, fue integrado al marco
argumentativo provisto por \textit{DeLP}.

\subsection{Construcción de argumentos de deseo}

La construcción de un argumento de deseo se produce cuando el programa \textit{DeLP} es 
consultado por un deseo particular. Para esto, se busca una regla de deseo cuya cabeza sea
el modelo de deseo al que pertenece el deseo consultado. A partir de esta, se genera un 
argumento, como se introdujo en la sección %REFFFFFFF

Existen circunstancias que pueden impedir la construcción de un argumento para un determinado
deseo. En el proceso de construcción, \textit{DeLP} puede encontrarse con la imposibilidad de generar
una derivación rebatible. Por la forma en que fue diseñado el sistema, la única posibilidad de
que esto ocurra se debe a la falta de hechos, que deberían haber sido suministrados durante el
seteo de creencias, o se trata de predicados \textit{built in} que no pueden ser generados. 

\subsubsection{Falta de creencias}

El faltante de creencias puede ser causado por dos motivos. Por un lado, puede 
deberse a la incapacidad para calcularlas. Otra causa es que, en tiempo de seteo de creencias,
se descubran razones para creer que el deseo relacionado con la creencia ha dejado de tener 
sentido, por lo cual dicha creencia no es asertada de forma deliberada, imposibilitado a \textit{DeLP}
para generar el argumento.

Un ejemplo claro de este comportamiento es el de la creencia de distancias. Como fue explicado en 
\ref{sec:creenciasEspecificas}, se trata de la cantidad de turnos que cuesta un plan. A partir de un
deseo, se calcula un camino que culmine en el vértice al cual el agente desea ir. Puede suceder que 
este camino no exista, o sea, no sea posible generarlo a partir de la base de conocimiento del 
agente, siendo este caso el primero de los explicados más arriba. 

En la búsqueda de caminos, se podan las ramas de una determinada longitud. Esto se realiza para evitar
tiempos de ejecución excesivos, pero también porque un deseo que tenga asociado un plan con una 
longitud mayor a la determinada, deja de tener sentido. Éste comportamiento es el explicado en el 
segundo de los motivos para la falta de hechos.

\subsubsection{Condiciones insatisfechas}

Las reglas de deseos pueden tener condiciones establecidas sobre los valores relacionados al deseo,
o aserciones, que
si no son satisfechas impiden la construcción del argumento de deseo. Se trata de relaciones aritméticas,
implementadas a partir del predicado \texttt{is\_a\_built\_in}, y calculadas por demanda en Prolog.

Por ejemplo, puede ser utilizado para chequear en Prolog que un deseo de expansión a un vértice genera
algún beneficio, al condicionar a la diferencia de puntos de zona a ser positivo.

\subsection{Conflictos}

Los conflictos que puedan tener los argumentos de deseo pueden ser los típicos de \textit{DeLP},
presentados anteriormente, o
los pertenecientes al modelo de argumentación. Estos últimos son los conflictos suscitados entre 
los argumentos de deseos entre sí, implementados en el modelo con las \textit{reglas de cancelación
mutua}. En la implementación del sistema, este comportamiento fue simulado desde Prolog, por lo que 
no fueron necesarias éstas reglas. En la sección siguiente se explicará cómo fue simulado.

\subsection{Derrotas y Garantías}

Los únicos criterios de comparación usados fueron la \textit{especificidad} y la \textit{derrotador a 
asunciones}. Para los deseos que son garantizados por DeLP se generan sus respectivos árboles de dialéctica, como 
fue explicado en la sección %REFFFF
No fue necesario implementar el criterio \textit{Mayor peso}, ya que este comportamiento
fue simulado por la interfaz con Prolog.

Como fue explicado, en el modelo todos los argumentos de deseos se encuentran en conflicto, y el 
único que queda como no derrotado es el de mayor peso. Para simular ésto, Prolog consulta 
secuencialmente por todos los deseos, y va manteniendo el de mayor peso. Entonces, los otros deseos
quedan derrotados de manera implícita.



%El esquema modelo de un argumento de deseo es el que se encuentra en la Fig. 
%\ref{fig:modeloArgumento}. Algunos contienen variaciones con respecto a éste, pero
%la mayoría comparte esta estructura.
%
%\begin{figure}
%\begin{verbatim}
%% "Vertice" es el vertice al cual se quiere expandir
%aumento(Peso, Vertice) -< 
%    % 1 - Primero se colocan las creencias binarias (sí o no).
%    
%    esSeguro(Vertice), 
%    
%    % 2 - Luego, las creencias difusas.
%    % Éstas tienen pueden estar asertadas o no. Si no lo están, significa
%    % que no se encontró su valor. Por ejemplo, en el caso de la distancia,
%    % si no se encuentra es porque no se encontró camino.
%    
%    b(distancia(Vertice, [], Dist, EnergyLeft)),
%    b(difPuntosZona(Vertice, DifPuntos)),
%    
%    % 3 - Pueden existir razones fuertes para descartar el deseo.
%    % En este caso, se trata de que no se considerará expandirse a un 
%    % vértice que disminuya la cantidad de puntos.
%    
%    greater(DifPuntos, 0),
%    
%    % X - Puede haber modificadores, como coeficientes.
%    
%    phaseCoef(aumento, Coef),
%    
%    % 4 - Finalmente, se calcula el peso, con todos los valores.
%    
%    aumentoValue(Dist, DifPuntos, EnergyLeft, Coef, Peso).
%\end{verbatim}
%\caption{Modelo de deseo. Los números en los comentarios representan los posibles 
%puntos de ataque.}
%\label{fig:modeloArgumento}
%\end{figure}
%
%En el proceso de selección de intención, se atacan, como fue explicado anteriormente,
%explícita o implícitamente los deseos, ya sea por razones propias 
%para rechazarlo, o por peso. Los puntos de ataque se encuentran expuestos en la Fig. 
%\ref{fig:modeloArgumento}.
%
%\subsection{Derrotas propias}
%
%Un deseo puede ser desechado por razones propias. En esta sección se expondrán estos
%posibles puntos de ataques.
%
%En la jerga de DeLP, una derrota propia es aquella en la cual uno de los dos 
%argumentos que entra en conflicto sale victorioso (se mantiene \emph{undefeated}),
%mientras que el otro es derrotado. En nuestro contexto, consideramos a las 
%``derrotas propias de argumentos de deseos'' como ``derrotas por razones propias''. 
%O sea, se trata de razones por las cuales un argumento de deseo no es seleccionado
%para ser la siguiente intención a llevar a cabo.
%
%\subsubsection{Falta de hechos}
%\label{sec:faltaDeHechos}
%
%Para los dos primeros puntos del modelo se necesitan hechos previamente asertados 
%por el programa Prolog. La falta de estos corresponde con que no pudieron ser 
%encontrados, por alguna razón, y por lo tanto impedirán que cualquier deseo 
%relacionado no pueda considerarse como válido.
%
%La consulta en DeLP de un literal en cuyas reglas no se puede satisfacer por lo
%menos una de las precondiciones, devuelve 
%\texttt{undecided}, ya que no pertenece al conjunto de literales sobre los cuales
%el programa DeLP puede determinar su veracidad o falsedad. Nuestra idea fue 
%considerar estos resultados de la misma manera que con los que devuelvo \texttt{no}
%como respuesta, por lo que, dentro de nuestro sistema, estos ``argumentos'' son
%considerados como derrotados por razones propias.
%
%\subsubsection{Precondiciones negadas}
%
%Las precondiciones pueden ser encontradas, pero negadas. Esto significa que existen
%razones para creer exactamente lo contrario de lo que el argumento de deseo 
%necesita para ser considerada válida. Generalmente, este tipo de derrotas se 
%encuentran en el punto 1 de la Fig. \ref{fig:modeloArgumento}, pero pueden 
%encontrarse también en el punto 3. En estos casos, la consulta sí devuelve 
%\texttt{no} como respuesta.
%
%En el caso de \texttt{esSeguro/1}, se define que cualquier vértice es por defecto
%seguro, salvo que se especifique lo contrario (esto es, se aserte un hecho
%\texttt{~esSeguro}). En Prolog se especificará que un vértice no es seguro cuando
%un saboteador enemigo habiilitado se encuentre parado sobre éste.
%
%\subsubsection{Valores inválidos}
%
%El punto de ataque 3 se conforma de reglas que establecen parámetros estrictos
%sobre los valores que se obtienen en el punto 2. Se trata de aserciones, no en el 
%sentido \textit{prologiano}, sino como una condición que deben cumplir los valores. 
%
%En el caso del ejemplo de la Fig.
%\ref{fig:modeloArgumento}, se desechan los vértices hacia los cuales moverse 
%implica no ganar puntos, o sea, el valor obtenido en \texttt{difPuntos}\ es no
%positiva. Esto es porque no tiene sentido el concepto de \emph{aumentar} una zona
%si se pierden puntos.
%
%Se trató de evitar usar este sistema, no porque éste sea ineficiente, sino 
%porque este tipo de chequeos pueden realizarse en Prolog, y, siendo el caso que
%no lo pasaran, simplemente no aserta la creencia en cuestión. Además, se puede
%ahorrar el cálculo de las siguientes creencias relacionadas con el deseo. De esta
%manera, la derrota caería en el caso explicado en la sección 
%\ref{sec:faltaDeHechos}.
%
%\subsection{Derrotas por Peso}
%
%Siendo el caso que no se genere ninguno de los tipos anteriores de derrotas, el
%deseo es un deseo válido, o sea, para tener en cuenta. Entonces, su consulta 
%devolverá \texttt{yes}, con su peso asociado, y entrará en conflicto con el resto
%de los deseos válidos.
%
%Como fue explicado en la sección \ref{sec:interfazConProlog}, la interfaz con 
%Prolog mantiene el deseo con mayor peso hasta que consigue otro que lo destrone.
%De esta manera, implícitamente se genera una derrota fuera de DeLP entre 
%argumentos de deseo, en la cual sólo gana uno. (En el caso que se encuentre un 
%deseo con el mismo peso que el actual, éste se mantiene.) Se puede considerar
%que el punto de este tipo de ataque es el punto 4 de la Fig. 
%\ref{fig:modeloArgumento}, ya que es donde se calcula el peso del argumento.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\chapter{Detalles de la Implementación}

Hasta aquí, se han presentado el marco teórico sobre el cual se trabajó, el contexto
de la competencia, y la manera en que hemos abordado el problema de la selección de
intenciones. A pesar de haber utilizado algunos ejemplos propios del código de los 
agentes, no se han explicado en detalle los diferentes deseos utilizados, y los 
detalles de implementación de éstos, como las decisiones de diseño tomadas.

En este capítulo se abordarán estos temas, de manera tal de mostrar el extenso 
trabajo realizado para la competencia.

\section{Creencias}

\label{sec:creencias}

En el modelo BDI (\textit{Beliefs, Desires, Intentions}), el componente del conocimiento
del agente está determinado por el conjunto de las \textit{beliefs}, o creencias. En esta
sección, se definirán, clasificarán y listarán éstas.

\begin{definicion}
	Una \textbf{creencia} es un literal.
\end{definicion}

Esta definición no aporta muchas restricciones sobre lo que en realidad es una creencia.
Esto es porque la diferenciación con otros literales es puramente semántica.

Una creencia será un literal que contenga información útil sobre el agente. Puede estar
explícita en el programa (asertada), como puede ser generada a partir de reglas. A su vez,
puede residir tanto en Prolog como en DeLP.

Las \textbf{creencias simples}\ será todo aquello que sólo necesite una consulta, y no
una computación extensa. Éstas son aquellas que vengan directamente de la percepción. 
Otras creencias deben ser computadas previamente antes de ser consultadas, ya que no
son triviales. Muchas se generan de una manera compulsiva, o sea, se calculan siempre,
que llamaremos \textbf{creencias generales},
y otras se calculan sólo cuando tienen un deseo asociado, o \textbf{creencias 
especìficas}.


\subsection{Creencias simples}


Para éstas, muchas veces se utilizó una consulta directa a Prolog,
utilizando el predicado \verb@is_a_built_in@, de manera tal de no tener que 
re-asertarlos en forma de hechos DeLP. En la Fig. \ref{fig:creenciasSimples}\ se ven
algunos de los hechos utilizados.

\begin{figure}
\begin{verbatim}
is_a_built_in(role(_, _)).
is_a_built_in(position(_, _)).
is_a_built_in(myMaxHealth(_)).
is_a_built_in(myHealth(_)).
is_a_built_in(myRole(_)).
is_a_built_in(myEnergy(_)).
is_a_built_in(myPosition(_)).
is_a_built_in(myStatus(_)).
is_a_built_in(myTeam(_)).
is_a_built_in(myName(_)).
is_a_built_in(currentStep(_)).
\end{verbatim}
\caption{Algunas de las creencias simples utilizadas.}
\label{fig:creenciasSimples}
\end{figure}





\subsection{Creencias generales}

\label{sec:creenciasGenerales}

Estas creencias son necesarias siempre, ya sea que lo sean para el seteo de 
\textit{beliefs}, y/o para la toma de decisiones, ya sea que se use en la mayoría
de los deseos, o en deseos que se calculen siempre. Por esta razón, se calculan
de manera compulsiva todos los turnos.


\subsubsection{Vértices alcanzables}

En la búsqueda de caminos para realizar las diferentes intenciones, no tiene sentido
extender demasiado la búsqueda a caminos de una longitud considerable, ya que el 
estado del mapa es muy cambiante, y muy probablemente dejarían de tener sentido. Por
esta razón, todos los turnos se calcula la distancia de cada vértice 
\textbf{alcanzable}\ y se almacena como un hecho Prolog, para ser usado en el 
cálculo de los deseos.

\begin{definicion}
Un vértice será \textbf{alcanzable}\ si está a una distancia menor a $D$, donde $D$
será un parámetro del sistema, previamente asignado.
\end{definicion}

Este cálculo se realiza en un solo \textit{breadth first search}, asertando los hechos
\texttt{verticeADistancia/2}. En versiones previas del sistema, en el seteo de deseos
se calculaban estas distancias, realizando una búsqueda por cada esquema de deseo, 
pero se optó por este método para realizar una sola búsqueda.


\subsubsection{Vértices visibles y explorados}

Para determinar el estado de conocimiento del mapa, tanto de las conexiones
entre vértices, como del conomiento actual, en todos los turnos se calculan
lo que hemos denominado como \texttt{vértices explorados} y \texttt{vértices 
visibles}. 

\begin{definicion}
Un vértice será considerado \textbf{explorado}\ por el equipo $X$ si en algún 
turno menor o igual al actual haya estado a una distancia menor a $r$ del agente
$A$, siendo el agente $A$ miembro de $X$, y $r$ el rango de visión de $A$.
\end{definicion}

Bajo esta definición, se puede asegurar que si un vértice está explorado, se 
conocen todos sus vecinos. En el caso trivial, cualquier vértice que haya sido
pisado alguna vez por algún agente estará explorado, ya que todos tienen por lo 
menos un rango de visión igual a 1. Luego, si es igual a 2, se considerarán
explorados tanto su posición, como los vecinos de éste.

A la hora de calcular el puntaje del mapa utilizando el algoritmo de coloreo,
es importante tener en cuenta que no se conoce todo el mapa, lo que es conocido 
como \textit{fog of war}. Para esto, se debe determinar el estado de visibilidad
de los vértices conocidos. 

\begin{definicion}
Un vértice será \textbf{visible}\ en el turno actual para el equipo $X$ si se 
encuentra a distancia 
menor a $r$ del agente $A$, siendo $A$ un miembro de $X$, y $r$ el rango de visión 
de $A$. También será considerado visible si está explorado, y para cada vecino suyo 
existe por lo menos un agente que lo tiene dentro de su rango de visión.
\end{definicion}

De esta manera, nos aseguramos de que todo aquel vértice al cual sea considerado 
como visible, para todo vecino suyo existe por lo menos un agente del equipo 
que lo ve. Podemos observar también que la definición de visible es más fuerte que
de explorado.

Para estos dos conceptos, existen otros dos, que se refieren a sus negaciones. O 
sea, existen las creencias de si los vértices están tanto \textbf{no explorados}
o \textbf{no visibles}, que son actualizadas debidamente.


\subsubsection{Puntajes}

Utilizando nuestra implementación del algoritmo de coloreo, se calculan algunas
creencias necesarias para realizar otros cálculos. La primer consulta se hace con
el mapa tal cual se recibe en la percepción, de manera tal de obtener el puntaje
actual, el cual será utilizado como referencia para calcular las diferencias de
puntajes dados por movimientos de los agentes. Este valor se utiliza solamente
en Prolog, esto es, no en DeLP, y se almacena en el hecho \texttt{b(puntajeActual)}.

Se podría utilizar el puntaje que se obtiene en la percepción, ahorrándose
su computación. Se decidió no realizarlo de esta manera, ya que el algoritmo de 
coloreo puede dar un resultado erróneo, al ser una aproximación por realizarse
sobre un mapa incompleto. De esta manera, como sólo interesa la diferencia 
relativa, ésta será calculada sobre dos magnitudes obtenidas con el mismo 
método.

La creencia que sí es almacenada como hecho DeLP es la diferencia de puntos entre
el mapa sin la presencia del agente, y el mapa actual, al cual denominamos
\texttt{difPuntosSinMi}.


\subsubsection{Frontera}

Conocer la frontera de la zona del equipo es un dato importante para los agentes,
ya que un movimiento incorrecto de un agente que se encuentre en ésta puede 
generar una baja considerable del puntaje de zona. Por esta razón, definimos a
la frontera de la siguiente manera:

\begin{definicion}
Un vértice $V$ se encuentra en la frontera de la zona del equipo $X$, si $V$ 
pertenece a la zona de $X$, existe un vecino $V'$ de $V$ que pertenece a la zona 
de $X$, y existe un vecino $V''$ distinto de $V'$ que no pertenzca al equipo $X$. 
O sea, puede ser que no pertenezca a ningún equipo, o al equipo enemigo.
\end{definicion}

Esto queda almacenado en el hecho Prolog \texttt{b(frontera(Vertice))}, para ser
utilizado luego en el seteo de deseos.

\subsection{Creencias específicas}

\label{sec:creenciasEspecificas}

El conjunto de las creencias específicas se calcula \textit{por demanda}, o sea, 
cada vez que es necesario calcularlo, ya que no siempre son requeridas. Dependen
de que un deseo las utilice, para ser calculadas. Las que se explicarán en está
sección serán aquellas que sean utilizadas por dos o más deseos. Si son 
utilizadas por un solo deseo, se explicará junto a éste en el próximo capítulo.

\subsubsection{Distancias a vértices}

Las distancias a los vértices considerados por los distintos deseos son tenidas en 
cuenta en la selección de intenciones, es por esto que necesitan ser calculadas.
El algoritmo de búsqueda de caminos no obtiene las distancias físicas a los vértices.
Por el contrario, su espacio de búsquedas es un grafo implícito, compuesto por estados
y transiciones. Las transiciones representan las acciones que el agente emplea
para moverse (\texttt{goto} y \texttt{recharge}), y los estados están formados por 
la energia del agente, su posición, y las acciones que ha realizado. La energía se ve
afectada por cualquiera de las acciones, y la posición solo por la acción \texttt{goto}.
Las acciones son insertadas al final de la lista.

El estado inicial de la búsqueda consiste en la energía del agente, su posición, y una 
lista de acciones vacía. Por último, el costo del camino se calcula como la cantidad de 
acciones que posee la lista.

Dado que no se cuenta con la información necesaria para determinar una heurística, se 
utilizó un \textit{Uniform Cost Search} (UCS). Esta búsqueda expande primero el estado
de la frontera de menor costo.

Teniendo en cuenta que cada camino se obtiene para una meta particular, este debe ser
completado con la acción final a realizar. Al final de la lista se insertan los 
\texttt{recharge} necesarios para que el agente se encuentre en condiciones de realizar 
dicha acción, y luego se inserta la acción en cuestión.

La distancia calculada se almacena en el predicado:

\begin{verbatim}
b(camino(NodoFinal, AccionesARealizar, SecuenciaDeVértices, Plan, 
   Distancia, EnergíaRestante))
\end{verbatim}

Y este es el hecho DeLP utilizado en la argumentación:

\begin{verbatim}
b(distancia(X, [Acciones], Distancia, EnergiaRestante)) <- true.
\end{verbatim}

\subsubsection{Diferencia de puntos}

Otro dato almacenado es la diferencia de puntos que pueden generar los distintos
movimientos posibles del agente. Para esto, se ubica hipotéticamente al agente
en las distintas posiciones, y se aplica el algoritmo de coloreo para determinar
la suma de puntos que obtendría el agente con cada desplazamiento. El resultado
se resta al puntaje actual para obtener la diferencia.

\subsection{Creencias Defensivas}

Dado que en cualquier momento un agente puede ser atacado por algún saboteador 
enemigo, se deben generar creencias que establezcan si el agente ha sido herido.
Para esto, se calcula si el agente perdió vida en el último turno. Puede suceder
que el agente se haya movido de vértice en la última acción, y que esta haya sido
satisfactoria, y en tal caso se considerará que el agente no está en un vértice
peligroso. Si esas condiciones no se cumplen, se asertará la creencia 
\texttt{mePegaron}.

Otro dato importante es la posición de los saboteadores habilitados enemigos.
Éstos son asertados en la creencia \texttt{b(haySaboteador(Posicion))}, donde 
\texttt{Posicion}\ es la posición de dicho agente.

\section{Deseos}

Como se expuso anteriormente, existe un conjunto de modelos de deseos, especificados
previamente en la implementación, las cuales se instanciarán en deseos, y entre los 
cuales se seleccionará a la intención a llevar a cabo por el agente.

\subsection{Deseos Comunes}

A pesar de tener un comportamiento distinto determinado por los roles, los agentes
tienen un grueso cuerpo de código común, tanto en la arquitectura general, como 
en la parte argumentativa. De esta manera, la mayoría de los deseos implementados son
compartidos por todos los agentes, y representan los comportamientos comunes de éstos.

\subsubsection{Quedarse}

El deseo más básico de los agentes es el de \textbf{Quedarse}, ya que genera un plan de 
una única acción, la cual puede ser un \texttt{recharge}\ o un \texttt{skip}, las cuales
mantienen al agente en el lugar, y optimizan la energía de éste. La 
motivación de tener este deseo es tener que, no importa la situación del agente, éste
siempre tenga por lo menos un deseo para seleccionar como intención.

Tiene dos reglas que lo modelan, como se ve en la Fig. \ref{fig:deseoQuedarse}. Por un
lado, la primera es siempre verdadera, ya que no tiene precondiciones (es una asunción).
La segunda depende de la creencia \texttt{difPuntosSinMi}, y que el agente se encuentre
en la zona. La idea es que, en el caso que el equipo se encuentre en una zona muy buena,
el agente tenga mayores razones para no moverse. Esto se puede ver en el cálculo del 
peso, en la última regla del código de la figura. Por último, la tercer regla es una
regla de cancelación, para evitar que dos argumentos de deseo se generen para el mismo
deseo, con posiblemente pesos distintos, quedándose con el mayor.

\begin{figure}
\begin{verbatim}
quedarse(20) -< true.

quedarse(Peso) -< 
    b(difPuntosSinMi(SinMi)),
    myName(Agente),
    agenteEnZona(Agente),
    quedarseValue(SinMi, Value).

~quedarse(Peso) <-
    quedarse(Peso2),
    greater(Peso2, Peso).

quedarseValue(SinMi, Value) :-   
    Value is -SinMi * 5.
\end{verbatim}
\caption{Implementación del deseo \textbf{Quedarse}.}
\label{fig:deseoQuedarse}
\end{figure}


\subsubsection{Explorar}

El deseo de \textbf{explorar}\ se refiere a conocer más el mapa. Es disparado para 
conocer mejor las conexiones entre los vértices (arcos). Se instancia con los vértices
que se encuentran en la frontera del mapa conocido, o sea, en los nodos que se sabe
que existen, pero no necesariamente se conocen todos sus arcos. Para esto, se tienen en 
cuenta los vértices no explorados, utilizando la definición explicada en la 
sección \ref{sec:creenciasRegulares}. El plan que genera 
consiste en una serie de \texttt{goto}\textit{'s}\ hasta llegar al vértice en cuestión, y 
culmina con un \texttt{survey}.

% lo saco porque fue explicado en la parte de vértices explorados y visitados

% Estos nodos no explorados se calculan en el programa Prolog, teniendo en cuenta los 
% nodos agregados al mapa conocido por la última percepción. Se tendrán en cuenta sólo
% aquellos que se encuentren a una distancia $r - 1$ del nodo del agente, siendo $r$
% el rango de visión de éste. Un vértice explorado se mantendrá así por todo el 
% transcurso del partido.

Como se observa en la Fig. \ref{fig:deseoExplorar}, utiliza los datos de cantidad de 
turnos que costará el plan, y la diferencia de puntos.
El deseo está dividido en dos con respecto a esta última creencia. En el caso que la
cantidad de turnos sea poca (menor a 3), se considerará la creencia 
\texttt{difPuntosZona}. En cambio, si es mayor o igual a 3, se utilizará la creencia
\texttt{difPuntosSinMi}. Esto es porque tiene sentido considerar la suma de puntos
de zona sólo si sucede en pocos turnos, ya que en más el mapa cambiará 
considerablemente. 

El deseo deja de tener sentido cuando el vértice es explorado por otro agente del propio
equipo. 

\begin{figure}
\begin{verbatim}
explorar(Peso, X) -<
    b(distancia(X, [[survey]], Dist, EnergiaRestante)),
    greaterEq(Dist, 3),
    b(difPuntosSinMi(DifPuntos)),
    positivoONegativo(DifPuntos, Positivo, Negativo),
    phaseCoef(explorar, Coef),
    explorarValue(Dist, Positivo, Negativo, EnergiaRestante, Coef,
    	Value).
\end{verbatim}
\caption{Implementación parcial del deseo \emph{Explorar}}
\label{fig:deseoExplorar}
\end{figure}
% 
% \begin{figure}
% \begin{verbatim}
% explorarValue(Dist, Positivo, Negativo, EnergyLeft, Coef, Value) :-
%     Value is (20 + 2 ((10 - Dist) ** 2) + Positivo 
% 	      - Negativo ** 2 + EnergyLeft) Coef.
% \end{verbatim}
% \caption{Fórmula para el cálculo del peso del deseo \emph{Explorar}. 
% Recordar que en \emph{Prolog}\ el doble asterísco representa la potencia.}
% \label{fig:formulaExplorar}
% \end{figure}

\subsubsection{Aumentar Zona}

Para aumentar puntos de zona, los agentes deben ser capaces de elegir vértices a los 
cuales moverse, de manera tal de optimizarlos. Para esto, se utiliza el deseo de 
\textbf{Aumento}, el cual es instanciado con los vértices a los cuales sería posible ir y 
aumentar. 

Utiliza como datos de entrada la cantidad de turnos que utiliza el plan generado, el 
cual termina sin ninguna acción en particular, o sea, sólo cuenta con las acciones 
de traslación. A su vez, utiliza la diferencia de puntos que genera el movimiento, y 
se asegura que ésta sea positiva; de lo contrario no tendría sentido el deseo. Por 
último, necesita que el vértice destino sea seguro.

Es importante notar que el plan generado por el módulo de \textit{planning}\ no contiene
nodos inseguros. Este comportamiento es introducido en la generación de las creencias,
utilizando el concepto de falla del algoritmo de búsqueda, asertando una de estas reglas,
que falle cuando dicho algoritmo expanda un nodo inseguro.


\subsubsection{Reagruparse}

Para ahorrar tiempo de ejecución, el deseo anterior limita la búsqueda de caminos mayores
a cierta longitud, y, además, los caminos largos pero válidos generan un peso menor que 
los caminos cortos, para priorizar estos últimos. En el caso que, por alguna razón, un 
agente haya quedado lejos del resto de sus compañeros, será difícil que este vuelva en 
algún momento a formar una zona, teniendo sólo este deseo. Por esta razon, se agregó el
esquema de deseo de \textbf{Reagruparse}.

En la Fig. \ref{fig:deseoReagruparse}, se puede observar en primer lugar que el esquema 
de deseo no tiene ningún parámetro aparte del peso. Ésto es porque se decidió que tenía 
sentido sólo considerar un solo lugar al cual dirigirse, en caso de que se seleccione 
este deseo, y sería el vértice más cercano que pertenezca a la zona del equipo. Para 
ésto, se utilizó un par de creencias que no fueron explicadas anteriormente. Se trata de 
\textit{Distacia a Zona} y \textit{Agentes en Zona}.


\begin{figure}
\begin{verbatim}
reagruparse(Peso) -< 
    b(distanciaAZona(DistaciaZona)),
	b(agentesEnZona(AgentesEnZona)),
    phaseCoef(reagruparse, Coef),
    reagruparseValue(DistaciaZona, AgentesEnZona, Coef, Value).
\end{verbatim}
\caption{Implementación del deseo \textbf{Reagruparse}.}
\label{fig:deseoReagruparse}
\end{figure}


\paragraph{Distancia a Zona.}

Se trata de una creencia de distancia, la cual, al ser calculada, invoca al algoritmo
de búsqueda de caminos, para que encuentre el camino más corto hasta la zona. Ésta 
distancia, a diferencia de la utilización común en los otros deseos, afecta de manera 
positiva al puntaje de \textbf{Reagruparse}.

\paragraph{Agentes en Zona.}

Esta creencias simplemente calcula la cantidad de agentes que se encuentran en la zona
del equipo. Afecta de manera inversamente proporcional al peso del deseo, ya que al 
haber más agentes en zona, menos sentido tiene reagruparse.

\vspace{\baselineskip} 
Este esquema de deseo puede presentar problemas en el caso que todos los agentes se 
encuentren formando zonas de manera separada, en parejas. Evitar este comportamiento
implicaba muchas complicaciones, por lo que se optó por dejarlo funcionando así, ya
que en las pruebas los agentes se comportaban correctamente.


\subsubsection{Defensa Propia}

Cuando la salud de un agente es reducida a cero, debido a los ataques de 
agentes saboteadores enemigos, queda deshabilitado, perdiendo así la mayoría 
de sus capacidades y perjudicandodirectamente al equipo. Por esta razón, los 
agentes deben tener la habilidad de reconocer situaciones de peligro, y, de 
ser posible, superarlas. Con este objetivo, se cuenta con el deseo 
\textbf{Defensa Propia}.

Son utilizadas dos reglas para implementar el deseo, como se aprecia en la Fig. 
\ref{fig:deseoDefensaPropia}.
La primera, instanciada únicamente con la posición del agente, modela el caso en que este se 
encuentra en la misma posición que un saboteador enemigo, y está en condiciones de realizar 
la acción de bloquear un ataque (\texttt{parry}), En esta situación, existen razones para 
creer que la mejor defensa consiste en el bloqueo del posible ataque, y es por eso que el 
deseo recibe un peso preestablecido muy elevado (1000). 

La segunda regla es instanciada con aquellos vértices adyacentes a la posición del agente,
dado que representan los lugares de escape más cercanos. Tanto la distancia (en cantidad de 
turnos requeridos), como la diferencia de puntos producida son tenidas en cuenta para 
determinar el peso. El plan, en este caso, consiste en las acciones \texttt{recharge}\ y 
\texttt{goto} necesarias para llegar al nodo en cuestión.

\begin{figure}
\begin{verbatim}
defensaPropia(1000, Nodo) -<
    miEstado(normal),    
    puedoHacerParry,
    miPosicion(Nodo),
    haySaboteador(Nodo).

defensaPropia(Valor, Nodo) -<
    miEstado(normal),    
    miPosicion(MiPos),    
    haySaboteador(MiPos),
    b(difPuntosZona(Nodo, DifPuntos)),
    b(distancia(Nodo, [], Dist, EnergiaRestante)),
    valorDefensaPropia(DifPuntos, Dist, EnergiaRestante, Valor).
\end{verbatim}
\caption{Implementación del deseo \textbf{Defensa Propia}.}
\label{fig:deseoDefensaPropia}
\end{figure}
	
\subsubsection{Buscar Auxilio}
	
Cada ataque que un agente recibe, reduce su \textit{salud}, lo cual, como se mencionó, 
puede resultar en que el agente quede deshabilitado. La única forma de recuperar la 
salud perdida, es recibir la ayuda de un agente reparador. El deseo \textbf{Auxilio} 
es instanciado con los agentes reparadores del equipo, y tiene como finalidad lograr 
el acercamiento del agente dañado a alguno de ellos.

Para el pesaje, se considera como un factor importante el nivel de daño que ha sufrido 
el agente, calculado como el cociente entre su salud actual y la máxima posible. 
Además, como en otros casos, son utilizadas la diferencia de puntos (restando especial
valor en caso de ser negativa), y la distancia a la posición del reparador buscado. Dado que 
la acción de reparar no es responsabilidad del agente, el plan está compuesto sólo por las
acciones \texttt{goto}\ y \texttt{recharge} necesarias para alcanzar la ubicación del 
reparador, a la espera de su ayuda.

\begin{figure}
\begin{verbatim}
auxilio(Valor, Reparador) -<
	posicion(Reparador, Nodo),
	miMaximaSalud(MaximaSalud),
	miSalud(Salud),
	b(difPuntosSinMi(DifPuntos)),
	positivoONegativo(DifPuntos, _Positivo, Negativo),
	b(distancia(Nodo, [], Distancia, EnergiaRestante)),
	valorAuxilio(Distancia, EnergiaRestante, MaximaSalud, Salud, 
		Negativo, Valor).  	
\end{verbatim}
\caption{Implementación del deseo \textbf{Auxilio}.}
\label{fig:deseoAuxilio}
\end{figure}	



	
\subsubsection{Comprar}

Existen una serie de paquetes de extensión que los agentes, según sus roles, pueden 
adquirir durante una simulación, por un monto que es descontado de la reserva en dinero
del equipo. Se trata de sensores, baterías, escudos y dispositivos de ataque, que permiten 
al comprador incrementar su \textit{salud máxima}, \textit{energía máxima}, 
\textit{rango de visión}, y \textit{fuerza}, respectivamente.

El deseo \textbf{Comprar} cumple la finalidad de permitir al agente obtener estos paquetes,
de acuerdo a la necesidad de incorporarlos y a la situación del equipo, ya que el gasto 
de dinero afecta directamente a la puntuación del equipo en cada turno. El plan consiste 
únicamente en la acción de comprar (\texttt{buy}), que requiere como parámetro el item 
correspondiente.		
	
\subsection{Deseos Específicos}

Existen acciones que pueden ser ejecutadas sólo por agentes de un determinado rol. Esto da 
lugar al surgimiento de deseos que dependen exclusivamente de la capacidad de realizar 
ciertas acciones, y por lo tanto, que afectan sólo a algunos agentes específicos. Es por esto, 
que, además de los deseos comunes a todos los agentes del equipo, existe otro conjunto de 
deseos considerados sólo por algunos agentes en particular. En esta sección se presentan 
los deseos de este tipo.


\subsubsection{Sondear}

Los agentes \textit{exploradores} tiene la habilidad de sondear los vértices en 
búsqueda de agua, a través de la acción \texttt{probe}. Un vértice sin sondear 
que pertenezca a la zona del equipo concede a éste de sólo un punto por turno. 
Sin embargo, luego de ser sondeado concede todo su potencial, que es un valor 
entero aleatorio de 1 a 10. Por esta razón, es muy importante que los 
exploradores sondeen la mayor cantidad de nodos posibles, de manera tal de que 
todo el equipo cuente con esta información, la cual utilizará para tomar 
mejores decisiones a la hora de aumentar la zona.

\begin{figure}
\begin{verbatim}
sondear(Value, X) -< 
    b(distancia(X, [[probe]], Dist, EnergyLeft)),
    noSondeadoEnZona(X, EnZona),
    b(difPuntosZona(X, DifPuntos)),
    positivoONegativo(DifPuntos, Positivo, Negativo),
    phaseCoef(sondear, Coef),
    valorSondear(Dist, EnergyLeft, InZone, Positivo, Negativo, 
    	Coef, Value).
\end{verbatim}
\caption{Implementación del deseo \textbf{Sondear}.}
\label{fig:deseoSondear}
\end{figure}

En la Fig. \ref{fig:deseoSondear} se muestra la implementación de la regla de 
deseo. El esquema de este deseo es instanciado con los vértices que no hayan 
sido sondeados hasta el momento. A su vez, el hecho que el movimiento aumente
el puntaje de la zona influye positivamente en el peso de estos deseos.

Si el vértice no sondeado se encuentra en la zona, como fue explicado antes,
está aportando una cantidad menor de puntaje del que podría aportar, por lo 
cual el agente lo priorizará. Para ésto, se utiliza una creencia,
\textbf{No Sondeado en Zona}, la cual se puede observar en la Fig. 
\ref{fig:creenciaNoSondeado}. En el caso que el vértice se encuentre en la 
zona, esta creencia adicionará 50 puntos al peso del deseo. En su 
implementación, utiliza la creencia \textbf{En Zona}, no explicada hasta
ahora porque es también específica de este deseo, la cual lo único que 
indica es que el vértice se encuentra en la zona del equipo.

\begin{figure}
\begin{verbatim}
noSondeadoEnZona(_X, 0) -< true.
noSondeadoEnZona(X, 50) <- b(enZona(X)).
~noSondeadoEnZona(X, 0) <- noSondeadoEnZona(X, 50).
\end{verbatim}
\caption{Implementación de la creencia \textbf{No Sondeado 
en Zona}.}
\label{fig:creenciaNoSondeado}
\end{figure}

\subsubsection{Atacar}

Los agentes \textit{saboteadores}, como se dijo, tienen la capacidad de atacar a cualquier otro 
agentes enemigo, provocando la disminución de su \textit{salud}, si el ataque resulta exitoso.
Esto conlleva la posibilidad de atacar zonas del equipo contrario, causando daño a sus agentes, 
lo cual puede afectar su puntuación y estrategia, así como también resulta fundamental 
al momento de defender zonas propias de intrusos.

El deseo \texttt{Atacar} se instancia con aquellos agentes enemigos en estado normal (no deshabilidatos),
cuya posición en el turno anterior es conocida. Como se aprecia en la Fig. \ref{fig:deseoAtacar}, 
intervienen varios factores en el pesaje: los obtenidos a partir del cálculo de la distancia al 
agente, la diferencia de puntos que produce abandonar la posición actual, la importancia según el 
rol de la víctima (saboteadores y reparadores son priorizados), y la seguridad que ofrece la ubicación
actual (de acuerdo a la presencia de saboteadores enemigos). 

El plan para la intención de atacar se elabora uniendo las acciones necesarias para el desplazamiento
(\texttt{goto}\textit{'s} y \texttt{recharge}\textit{'s}) con la acción final \texttt{attack}, que 
tiene como parámetro el nombre del agente a ser atacado.

\begin{figure}
\begin{verbatim}
atacar(Valor, Agente) -<
    b(posicionEnemigo(Agente, Posicion)),
    b(distancia(Posicion,[[attack, Agente]], Turnos, 
    	EnergiaRestante)),
	b(difPuntosSinMi(DifPuntos)),
    rol(Agente, Rol),
	puntosPorRol(atacar, Rol, PuntosRol),
	posicionSegura(PuntosSeguro),
	valorAtacar(Turnos, EnergiaRestante, DifPuntos, PuntosSeguro, 
		Puntos, Valor).
\end{verbatim}
\caption{Implementación del deseo \textbf{Atacar}.}
\label{fig:deseoAtacar}
\end{figure}

\subsubsection{Reparar}

Así como los agentes dañados pueden ir en búsqueda de compañeros reparadores para recibir ayuda,
estos últimos deben ser capaces de salir al encuentro de agentes en problemas, y proceder con la 
reparación. Por este motivo, se cuenta con el deseo \texttt{Reparar}, que se instancia con todos 
los agentes del equipo con salud disminuida.

Como muestra la Fig. \ref{fig:deseoReparar}, para el cálculo del peso se tienen en cuenta los datos
relacionados al camino, junto con dos características especiales del agente: su estado (se prioriza 
a los agentes deshabilitados), y su rol (se prioriza a los agentes reparadores). El plan, como 
ocurre con otros deseos, se compone colocando la acción \textit{reparar} al final de la secuencia 
de acciones que dirigen al reparador a la posición del agente. La acción de reparar tiene el efecto 
de incrementar, en una cantidad fija, la \textit{salud} del agente reparado. 

\begin{figure}
\begin{verbatim}
reparar(Valor, Agente) -<
	b(infoSaludCompañero(Agente, Salud, MaximaSalud)),
	compañeroDeshabilitado(Salud, PuntosDeshabilitado),
    b(distancia(_Posicion,[[repair, Agente]], Turnos, 
    	EnergiaRestante)),
    role(Agente, Rol),
	puntosPorRol(reparar, Rol, PuntosRol),
    valorReparar(Turnos, EnergiaRestante, PuntosRol, Salud, 
	    MaximaSalud, PuntosDeshabilitado, Valor).
\end{verbatim}
\caption{Implementación del deseo \textbf{Reparar}.}
\label{fig:deseoReparar}
\end{figure}

%Explorar	    <-- X
%Aumento 		<-- X
%Defensa Propia <-- X
%Quedarse		<-- X
%Auxilio		<-- X
%Reagruparse    <-- X
%Comprar		<-- X
%
%Específicos
%
%Probe          <-- X
%Attack			<-- X
%Inspect        <--- LOLOLOLOL 
%Reparar		<-- X

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%  .-'---`-.
%,'          `.
%|             \
%|              \
%\           _  \
%,\  _    ,'-,/-)\
%( * \ \,' ,' ,'-)
% `._,)     -',-')
%   \/         ''/
%    )        / /
%   /       ,'-'

\end{document}
